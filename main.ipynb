{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n",
    "We will first load in the csv dataset that labels the images with their corresponding labels. We will convert them to lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv\n",
    "df = pd.read_csv('Training_set.csv')\n",
    "files = df['filename'].tolist()\n",
    "labels = df['label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the image paths\n",
    "We will get the path of the images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = './train/'\n",
    "\n",
    "image_paths = [os.path.join(image_path, f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./train/Image_1.jpg',\n",
       " './train/Image_2.jpg',\n",
       " './train/Image_3.jpg',\n",
       " './train/Image_4.jpg',\n",
       " './train/Image_5.jpg']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration through the images.\n",
    "We will now iterate and process the images. This is done by resizing them to (28, 28) and normalizing them, so that they can be fed into the model. Then we will add it to the X list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6499, 28, 28, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for image_path in image_paths:\n",
    "    img = image.load_img(image_path, target_size=(28, 28))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    X.append(img)\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get the `y` labels. We will turn it into an np array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SOUTHERN DOGFACE', 'ADONIS', 'BROWN SIPROETA', ..., 'APPOLLO',\n",
       "       'ELBOWED PIERROT', 'ATALA'], dtype='<U25')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(labels)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding the labels\n",
    "This is a function to convert the unique labels to numbers. This is so that we can use them in the model. Models don't understand strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(y):\n",
    "  \"\"\"\n",
    "  Converts string labels in a list to corresponding numbers based on their order of appearance.\n",
    "\n",
    "  Args:\n",
    "    y: A list of string labels.\n",
    "\n",
    "  Returns:\n",
    "    A list of integers representing the corresponding numbers for each label.\n",
    "    A dictionary mapping original string labels to assigned numbers.\n",
    "  \"\"\"\n",
    "\n",
    "  label_to_number = {}\n",
    "  counter = 0\n",
    "  numbered_y = []\n",
    "  for label in y:\n",
    "    if label not in label_to_number:\n",
    "      label_to_number[label] = counter\n",
    "      counter += 1\n",
    "    numbered_y.append(label_to_number[label])\n",
    "\n",
    "  return numbered_y, label_to_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_encoder(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y[0])\n",
    "y_to_number = y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will get the vocabulary of the labels. The size of it is 74. This will be important later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the model\n",
    "We will make the model. We will use the `Sequential` model. We will use `Conv2D`, `MaxPooling2D`, `Flatten`, `Dense` layers. We will use `adam` as the optimizer. We will use `Softmax` as the final layer for the model. This will make it a Convoluted Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(75, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the model\n",
    "We will compile the model. We will use `sparse_categorical_crossentropy` as the loss function which is suited for multi-class classification or the use of `softmax`. We will use `accuracy` as the metric. We will use `adam` as the optimizer to help it lower the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of the model\n",
    "This will show how many parameters are in our model, in this case it is going to be 233,995 parameters or 914 kb worth of weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 75)                9675      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 233995 (914.04 KB)\n",
      "Trainable params: 233995 (914.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We will train our model on the first 100 images so it will be easier and faster to train. We will train for 12 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 3.8037 - accuracy: 0.0878\n",
      "Epoch 2/10\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 2.6397 - accuracy: 0.2916\n",
      "Epoch 3/10\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 2.1570 - accuracy: 0.4088\n",
      "Epoch 4/10\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.8728 - accuracy: 0.4839\n",
      "Epoch 5/10\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.6678 - accuracy: 0.5388\n",
      "Epoch 6/10\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.4885 - accuracy: 0.5801\n",
      "Epoch 7/10\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.3288 - accuracy: 0.6180\n",
      "Epoch 8/10\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.1956 - accuracy: 0.6565\n",
      "Epoch 9/10\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.0868 - accuracy: 0.6842\n",
      "Epoch 10/10\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.9867 - accuracy: 0.7120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23f3d435960>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X[200:], y[200:], epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get the loss and accuracy of the model by evaluating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 1s 4ms/step - loss: 0.8987 - accuracy: 0.7383\n",
      "Loss: 0.8986737132072449, Accuracy: 0.7383407950401306\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X[2:], y[2:])\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = image.load_img('./train/Image_10.jpg', target_size=(28, 28))\n",
    "new_image = image.img_to_array(new_image)\n",
    "new_image = new_image / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The giant output of numbers is each label with the corresponding probability of the image being that label. The highest probability is the predicted label. In this case it is label `7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "[[2.43623643e-13 6.36725450e-10 3.98795555e-06 4.80462819e-01\n",
      "  6.11516839e-07 3.72646718e-05 1.66915967e-10 9.13807773e-04\n",
      "  8.23928981e-10 2.00935624e-09 2.70506528e-09 3.59644837e-05\n",
      "  5.79805237e-05 3.68725602e-03 1.85397364e-10 2.83455842e-10\n",
      "  7.23105855e-04 1.84829914e-05 2.88832166e-06 4.03661744e-07\n",
      "  1.75000227e-03 1.25619599e-12 2.10871492e-02 2.88111082e-08\n",
      "  6.28776888e-07 1.82032245e-09 2.23713315e-07 7.33753433e-04\n",
      "  7.35761940e-09 5.73871148e-07 2.70124478e-09 2.66308058e-03\n",
      "  8.72020493e-04 8.37439857e-03 1.74077968e-07 1.59148076e-05\n",
      "  5.06016149e-05 7.16417417e-05 2.24805990e-05 2.37360075e-01\n",
      "  9.84985745e-05 2.40755912e-06 6.98649600e-08 8.93153716e-04\n",
      "  9.97106895e-07 2.05631223e-09 2.60375174e-07 2.54428723e-09\n",
      "  2.67003173e-07 2.35449335e-07 1.55133804e-07 1.93688720e-06\n",
      "  1.33492313e-02 4.32315096e-02 1.12112255e-11 9.14368081e-10\n",
      "  1.56061396e-05 1.58536693e-07 1.94143271e-10 6.57165433e-10\n",
      "  1.61873970e-07 1.07212319e-08 7.87073441e-06 6.17242127e-04\n",
      "  1.08373728e-08 7.03722094e-07 5.14800847e-03 1.48585078e-03\n",
      "  1.97957997e-04 2.98012830e-12 3.72953248e-14 1.62378281e-01\n",
      "  1.35505246e-02 7.11929752e-05 3.75012490e-07]]\n",
      "Prediction: 3\n",
      "Label corresponding to prediction: 3\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(np.array([new_image]))\n",
    "print(prediction)\n",
    "print(f'Prediction: {np.argmax(prediction)}')\n",
    "# print label corresponding to prediction\n",
    "# Assuming you have the prediction stored in the variable 'prediction'\n",
    "label = np.argmax(prediction)\n",
    "print(f'Label corresponding to prediction: {label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
